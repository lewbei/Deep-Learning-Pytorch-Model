{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKaAENGK0ajV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from functools import partial\n",
        "from dataclasses import dataclass\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv2dAuto(nn.Conv2d):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n",
        "\n",
        "conv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)\n"
      ],
      "metadata": {
        "id": "TgrtXjez8hjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.in_channels, self.out_channels =  in_channels, out_channels\n",
        "        self.blocks = nn.Identity()\n",
        "        self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        if self.should_apply_shortcut: residual = self.shortcut(x)\n",
        "        x = self.blocks(x)\n",
        "        x += residual\n",
        "        return x\n",
        "\n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.out_channels"
      ],
      "metadata": {
        "id": "forFINRu1wwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "class ResNetResidualBlock(ResidualBlock):\n",
        "    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels)\n",
        "        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n",
        "        self.shortcut = nn.Sequential(OrderedDict(\n",
        "        {\n",
        "            'conv' : nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n",
        "                      stride=self.downsampling, bias=False),\n",
        "            'bn' : nn.BatchNorm2d(self.expanded_channels)\n",
        "\n",
        "        })) if self.should_apply_shortcut else None\n",
        "\n",
        "\n",
        "    @property\n",
        "    def expanded_channels(self):\n",
        "        return self.out_channels * self.expansion\n",
        "\n",
        "    @property\n",
        "    def should_apply_shortcut(self):\n",
        "        return self.in_channels != self.expanded_channels"
      ],
      "metadata": {
        "id": "7nsMRZK81w-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBasicBlock(ResNetResidualBlock):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, *args, **kwargs)\n",
        "        self.blocks = nn.Sequential(\n",
        "            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n",
        "            activation(),\n",
        "            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n",
        "        )\n"
      ],
      "metadata": {
        "id": "EWIiOHIz2C7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    ResNet encoder composed by increasing different layers with increasing features.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2],\n",
        "                 activation=nn.ReLU, block=ResNetBasicBlock, *args,**kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.blocks_sizes = blocks_sizes\n",
        "\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n",
        "            nn.BatchNorm2d(self.blocks_sizes[0]),\n",
        "            activation(),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n",
        "        self.blocks = nn.ModuleList([\n",
        "            ResNetLayer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation,\n",
        "                        block=block,  *args, **kwargs),\n",
        "            *[ResNetLayer(in_channels * block.expansion,\n",
        "                          out_channels, n=n, activation=activation,\n",
        "                          block=block, *args, **kwargs)\n",
        "              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]\n",
        "        ])\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.gate(x)\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "lxN4BOuO1-WS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    This class represents the tail of ResNet. It performs a global pooling and maps the output to the\n",
        "    correct class by using a fully connected layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, n_classes):\n",
        "        super().__init__()\n",
        "        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.decoder = nn.Linear(in_features, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.avg(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cACrephF18dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, n_classes, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.encoder = ResNetEncoder(in_channels, *args, **kwargs)\n",
        "        self.decoder = ResnetDecoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "24FWZSsA11Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetBottleNeckBlock(ResNetResidualBlock):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, activation=nn.ReLU, *args, **kwargs):\n",
        "        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n",
        "        self.blocks = nn.Sequential(\n",
        "           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1), activation(),\n",
        "             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling), activation(),\n",
        "             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1))"
      ],
      "metadata": {
        "id": "YFBVPPKOgrAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[2, 2, 2, 2])\n",
        "\n",
        "def resnet34(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBasicBlock, deepths=[3, 4, 6, 3])\n",
        "\n",
        "def resnet50(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 6, 3])\n",
        "\n",
        "def resnet101(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 4, 23, 3])\n",
        "\n",
        "def resnet152(in_channels, n_classes):\n",
        "    return ResNet(in_channels, n_classes, block=ResNetBottleNeckBlock, deepths=[3, 8, 36, 3])"
      ],
      "metadata": {
        "id": "kV3M6YRU16rP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, block=ResNetBasicBlock, n=1, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n",
        "        downsampling = 2 if in_channels != out_channels else 1\n",
        "\n",
        "        self.blocks = nn.Sequential(\n",
        "            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n",
        "            *[block(out_channels * block.expansion,\n",
        "                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.blocks(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "gt4XOsRa3cdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n",
        "    return nn.Sequential(OrderedDict({'conv': conv(in_channels, out_channels, *args, **kwargs),\n",
        "                          'bn': nn.BatchNorm2d(out_channels) }))"
      ],
      "metadata": {
        "id": "9RhDwrat3gMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "U-V5FzFQ3zkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(1,4).to(device)"
      ],
      "metadata": {
        "id": "jNVdFBYS2GcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}